name: TechCrunch Web Scrape Pipeline

on:
  schedule:
    - cron: "0 12 * * *"  # Every day at noon UTC
  workflow_dispatch:      # Allows manual trigger from GitHub UI

jobs:
  scrape-and-save:
    runs-on: ubuntu-latest

    env:
      PG_USER: ${{ secrets.PG_USER }}
      PG_PASSWORD: ${{ secrets.PG_PASSWORD }}
      PG_HOST: ${{ secrets.PG_HOST }}
      PG_PORT: ${{ secrets.PG_PORT }}
      PG_DB: ${{ secrets.PG_DB }}
      FIRECRAWL_API_KEY: ${{ secrets.FIRECRAWL_API_KEY }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run TechCrunch Scraper
        run: python notebooks/Techcrunch_Web_Scrape_Extract_Load_Raw.py

      - name: Upload article CSV
        uses: actions/upload-artifact@v3
        with:
          name: techcrunch-articles
          path: techcrunch_articles.csv
